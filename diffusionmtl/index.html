<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DiffusionMTL">
  <meta name="keywords" content="DiffusionMTL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <meta property="og:image" content="./static/img/logo.png"/> -->
  <!-- <link rel="image_src" href="./static/img/logo.png"> -->
  <!-- <link rel="icon"
        type="image/x-icon"
        href="./static/img/logo.png"/> -->

  <title>
    DiffusionMTL (CVPR2024): Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data
  </title>

  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EDF010G6PN');


  </script>


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
  <script type="text/javascript" src="https://code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
  <script src="https://unpkg.com/interactjs/dist/interact.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css"/>
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css"/>

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="stylesheet" href="./static/css/gradient_color.css">
  
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <!-- <div class="columns is-centered">
        <div class="column is-8 has-text-centered">
          <img src="static/figs/diffusion.png" height="100%" alt="logo"/>
        </div>
      </div> -->
      <div class="container has-text-centered">
        <h1 class="title is-1 publication-title">
          <h1 class="gradient-text">DiffusionMTL</h1> <font size="6">Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data </font> 
        </h1>
        <br> <font size="5">CVPR 2024</font>
        <div class="is-size-5 publication-authors">
          <div class="author-block">
            <a href="https://sites.google.com/site/yhrspace/">Hanrong Ye</a>,
          </div>
          <div class="author-block">
            <a href="https://www.danxurgb.net/">Dan Xu</a>
          </div>
        <div class="is-size-5 publication-authors">
          <span class="author-block">Department of Computer Science and Engineering, HKUST</span>
        </div>
        <!-- <div class="is-size-6 publication-authors">
          <span class="author-block"><sup>*</sup>Most work done during internship at Adobe Research</span>
        </div> -->

        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- PDF Link. -->
            <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2106.13228.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
            <span class="link-block">
                <!-- <a href="SegGen_arxiv.pdf" -->
                <a href="https://arxiv.org/abs/2311.03355"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
            </span>
            <span class="link-block">
              <a href="https://github.com/prismformore/DiffusionMTL"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Github</span>
                </a>
            </span>
            <!-- Dataset Link. -->
            <!-- <span class="link-block">
              <a href="https://github.com/google/hypernerf/releases/tag/v0.1"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="far fa-images"></i>
                </span>
                <span>Data</span>
                </a>
              </span> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/images/teaser.mp4"
                type="video/mp4">
      </video> -->
      <div class="columns is-centered">
        <div class="column is-8 has-text-centered">
          <img src="static/figs/concept.png" height="100%" alt="logo"/>
        </div>
      </div>
      <h2 class="subtitle has-text">
        <font color="#9e2e23"><b><i>DiffusionMTL</i></b></font> is a multi-task denoising diffusion framework for improving prediction quality under a partially annotated multi-task learning setting, where the initial multi-task predictions are noisy due to the severe lack of ground-truth supervision.  </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 18px;">
          <p>
            Recently, there has been an increased interest in the practical problem of learning multiple dense scene understanding tasks from partially annotated data, where each training sample is only labeled for a subset of the tasks. The missing of task labels in training leads to low-quality and noisy predictions, as can be observed from state-of-the-art methods. To tackle this issue, we reformulate the partially-labeled multi-task dense prediction as a pixel-level denoising problem, and propose a novel multi-task denoising diffusion framework coined as DiffusionMTL. It designs a joint diffusion and denoising paradigm to model a potential noisy distribution in the task prediction or feature maps and generate rectified outputs for different tasks. To exploit multi-task consistency in denoising, we further introduce a Multi-Task Conditioning strategy, which can implicitly utilize the complementary nature of the tasks to help learn the unlabeled tasks, leading to an improvement in the denoising performance of the different tasks. Extensive quantitative and qualitative experiments demonstrate that the proposed multi-task denoising diffusion model can significantly improve multi-task prediction maps, and outperform the state-of-the-art methods on three challenging multi-task benchmarks, under two different partial-labeling evaluation settings.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Video</h2>
        <div class="publication-video">
          <iframe width="640" height="480" src="https://www.youtube.com/embed/qzgdE_ghkaI"
                  title="YouTube video player" frameborder="0"
                  allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                  allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3 centered">Partially Annotated Multi-Task Learning Setting</h2>
    </div>
    <div class="container is-max-desktop">
      <img src="static/figs/partially_supervised_setting.png" height="100%" ></img>
      <h2 class="subtitle has-text">
      Each training sample contains labels for a subset of the studied tasks, rather than all tasks. 
      As there is a lack of multi-task labels for each training sample, the partially supervised multi-task learning problem is more challenging compared to the fully supervised multi-task learning problem.
      </h2>
      </div>
    </div>
  </div>
</section>

  <div class="columns is-centered has-text-centered">
    <h2 class="title is-3 centered">Framework</h2>
  </div>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <img src="static/figs/framework.png" height="100%" ></img>
      <h2 class="subtitle has-text">
      <b>Illustration of the proposed DiffusionMTL (Prediction Diffusion).</b> DiffusionMTL first uses an initial backbone model for producing starter prediction maps for all tasks. Then, to denoise the initial prediction maps and generate rectified maps, we propose a Multi-Task Denoising Diffusion Network (MTDNet). MTDNet involves a diffusion process and a denoising process.
      During training, the initial prediction map of the labeled target task is gradually degraded by applying noise, resulting in the noisy prediction map. Then, we utilize a Multi-Task Conditioned Denoiser (referred to as the “Denoiser”) to denoise iteratively over S steps, resulting in a clean prediction map that is supervised by the ground-truth label. For better learning of unlabeled tasks, we propose a Multi-Task Conditioning mechanism in the denoising process to stimulate information sharing across different tasks. During inference, the diffusion and denoising processes are applied to all tasks to produce denoised multi-task prediction maps.
      </h2>
      </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-8 has-text-centered">
          <img src="static/figs/fea_diffusion.png" height="30%" ></img>
        </div>
      </div>
      <h2 class="subtitle has-text">
      <b>Illustration of the proposed DiffusionMTL (Feature Diffusion). </b>Different from Prediction Diffusion, Feature Diffusion conducts noise decay and denoising on initial feature maps. The denoised feature maps are projected to the final prediction map with a task head after the denoising.
    </div>
  </div>
</section>


<div class="columns is-centered has-text-centered">
  <h2 class="title is-3 centered">Experiments</h2>
</div>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="./static/images/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="static/figs/qualitative_1.png" height="100%" ></img>
      <!-- <h2 class="subtitle has-text-centered"> -->
      <h2 class="subtitle has-text">
        <b><i>DiffusionMTL</i></b> effectively denoises the noisy prediction maps of both depth estimation and semantic segmentation maps on Cityscapes dataset.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-dark is-small">
  <div class="hero-body">
    <div class="container has-text-centered">

      <div id="results-carousel" class="carousel results-carousel">

        <div>
          <div class="results-item">
            <image src="static/figs/vis_reverse_process_cs_more_website.png"  style="padding-right: 200px; padding-left: 200px;"></image>
            <figcaption>Qualitative comparison of the initial multi-task predictions, decayed predictions, our denoised results, and ground-truth labels on Cityscapes under one-label setting. 
            </figcaption>
          </div>
        </div>

        <div>
          <div class="results-item">
            <image src="static/figs/vis_reverse_process_cs_more_website2.png" style="padding-right: 200px; padding-left: 200px;"></image>
            <figcaption>Qualitative comparison of the initial multi-task predictions, decayed predictions, our denoised results, and ground-truth labels on Cityscapes under one-label setting. 
            </figcaption>
          </div>
        </div>

    </div>

      <div class="columns is-centered has-text-centered">
        <div class="column is-three-quarters is-size-5">
          <p>
            Our DiffusionMTL is able to rectify noisy input and generate clean prediction maps. The model used in this comparison is trained on the Cityscapes dataset under the one-label MTPSL setting.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<hr/>



<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3 centered">Quantitative Results</h2>
      </div>
        <img src="./static/figs/compare_init.png"/>
      <h2 class="subtitle has-text">
      </h2>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-6 has-text-centered">
          <img src="./static/figs/different_steps.png" height="100%" alt="logo"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-7 has-text-centered">
          <img src="./static/figs/table1.png" height="100%" alt="logo"/>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-9 has-text-centered">
          <img src="./static/figs/table2.png" height="100%" alt="logo"/>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container content is-max-desktop">
    <h2 class="title">BibTeX</h2>
    <pre><code>@InProceedings{diffusionmtl,
  title={DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data},
  author={Ye, Hanrong and Xu, Dan},
  booktitle={CVPR},
  year={2024}
}</code></pre>
  </div>
</section>


<section class="section" id="acknowledgements">
  <div class="container content is-max-desktop">
  The website template was adapted from
    <a href="https://seggenerator.github.io/">SegGen</a>.
  </div>
</section>



<script type="text/javascript" src="./static/slick/slick.min.js"></script>
</body>
</html>
